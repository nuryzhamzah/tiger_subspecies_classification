{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Modelling - Tiger Subspecies Classification\n",
        "This section covers the responsibilities of the **Data Scientist**:\n",
        "- Build, train and evaluate 3 CNN models (ResNet50, DenseNet121, MobileNetV3Large)\n",
        "- Perform transfer learning with pre-trained ImageNet weights\n",
        "- Tune hyperparameters and observe model performance\n",
        "- Evaluate using accuracy, mean Average Precision (mAP), and training time"
      ],
      "metadata": {
        "id": "PgZx2bFxjJ2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgekI_pVjKzX",
        "outputId": "f1796384-a5e9-4289-d836-4c768f1765b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define source and destination paths\n",
        "src_path = '/content/drive/MyDrive/Colab Notebooks/Project AI/tiger_datasets'\n",
        "dst_path = '/content/tiger_datasets'\n",
        "\n",
        "# Copy the dataset only if it hasn't already been copied\n",
        "if not os.path.exists(dst_path):\n",
        "    print(\"🚀 Copying dataset from Google Drive to Colab local storage...\")\n",
        "    shutil.copytree(src_path, dst_path)\n",
        "else:\n",
        "    print(\"✅ Dataset already copied to local storage.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYr99ykRjN3U",
        "outputId": "d48dc18a-741b-4e97-d281-acade1c8c94a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Copying dataset from Google Drive to Colab local storage...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: ⚙️ Install and import all required libraries"
      ],
      "metadata": {
        "id": "dma9UwUtjSKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow matplotlib scikit-learn\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import ResNet50, DenseNet121, MobileNetV3Large\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import average_precision_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W10eK-sKjTIc",
        "outputId": "56ea6b89-1d8b-41af-eae1-896808eb7d72"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: 🖼️ Data Preprocessing\n",
        "\n",
        "Create data generators for training, validation, and testing datasets using `ImageDataGenerator`. This resizes images and scales pixel values for improved model performance."
      ],
      "metadata": {
        "id": "DFT-SmwbjYcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define base directory of dataset and image parameters\n",
        "base_dir = '/content/tiger_datasets'\n",
        "image_size = (224, 224)  # Input image size for pretrained models\n",
        "batch_size = 32          # Number of images per batch during training/testing"
      ],
      "metadata": {
        "id": "py5KsS3GjZVb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Count by Subspecies and Data Split"
      ],
      "metadata": {
        "id": "376aW1_uje_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define base directory\n",
        "base_dir = '/content/tiger_datasets'\n",
        "\n",
        "# Define splits\n",
        "splits = ['train', 'val', 'test']\n",
        "\n",
        "# Get list of subspecies (class names)\n",
        "subspecies_list = sorted(os.listdir(os.path.join(base_dir, 'train')))\n",
        "\n",
        "print(\"\\n📊 Image count by subspecies (across train, val, test):\\n\")\n",
        "\n",
        "# Loop through each subspecies\n",
        "for subspecies in subspecies_list:\n",
        "    total = 0\n",
        "    print(f\"🐅 Subspecies: {subspecies}\")\n",
        "    for split in splits:\n",
        "        split_path = os.path.join(base_dir, split, subspecies)\n",
        "        if os.path.exists(split_path):\n",
        "            count = len([\n",
        "                f for f in os.listdir(split_path)\n",
        "                if os.path.isfile(os.path.join(split_path, f))\n",
        "            ])\n",
        "        else:\n",
        "            count = 0\n",
        "        total += count\n",
        "        print(f\"  - {split.capitalize():<5}: {count}\")\n",
        "    print(f\"➡️  Total: {total}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EY2OGM9jhMH",
        "outputId": "03c38180-05b8-426b-e7f5-153185f41e3d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Image count by subspecies (across train, val, test):\n",
            "\n",
            "🐅 Subspecies: bengal_tiger\n",
            "  - Train: 416\n",
            "  - Val  : 87\n",
            "  - Test : 87\n",
            "➡️  Total: 590\n",
            "\n",
            "🐅 Subspecies: indochinese_tiger\n",
            "  - Train: 434\n",
            "  - Val  : 92\n",
            "  - Test : 93\n",
            "➡️  Total: 619\n",
            "\n",
            "🐅 Subspecies: malayan_tiger\n",
            "  - Train: 442\n",
            "  - Val  : 90\n",
            "  - Test : 92\n",
            "➡️  Total: 624\n",
            "\n",
            "🐅 Subspecies: siberian_tiger\n",
            "  - Train: 309\n",
            "  - Val  : 66\n",
            "  - Test : 67\n",
            "➡️  Total: 442\n",
            "\n",
            "🐅 Subspecies: south_china_tiger\n",
            "  - Train: 318\n",
            "  - Val  : 68\n",
            "  - Test : 69\n",
            "➡️  Total: 455\n",
            "\n",
            "🐅 Subspecies: sumatran_tiger\n",
            "  - Train: 557\n",
            "  - Val  : 119\n",
            "  - Test : 120\n",
            "➡️  Total: 796\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generators"
      ],
      "metadata": {
        "id": "96doM4kEjnXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Set your dataset base directory and constants\n",
        "base_dir = '/content/tiger_datasets'\n",
        "image_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Define generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    shear_range=0.2,\n",
        "    brightness_range=[0.7, 1.3],\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Create the data flows\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir, 'train'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir, 'val'),\n",
        "    target_size=image_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    os.path.join(base_dir, 'test'),\n",
        "    target_size=image_size,\n",
        "    batch_size=1,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frsnnTqLjoLq",
        "outputId": "488b06bb-d49b-495c-9e67-70365d6a727f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2476 images belonging to 6 classes.\n",
            "Found 522 images belonging to 6 classes.\n",
            "Found 528 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: 🧠 Model Training Function\n",
        "This function:\n",
        "- Adds classification layers on top of pre-trained base model\n",
        "- Trains for 50 epochs\n",
        "- Tracks training time"
      ],
      "metadata": {
        "id": "-q-vYtm4jsuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "import numpy as np\n",
        "\n",
        "def calculate_map(model, data_gen):\n",
        "    predictions = model.predict(data_gen, verbose=0)\n",
        "    true_labels = data_gen.classes\n",
        "    predicted_probs = predictions\n",
        "    one_hot_labels = np.zeros(predicted_probs.shape)\n",
        "    one_hot_labels[np.arange(len(true_labels)), true_labels] = 1\n",
        "    return average_precision_score(one_hot_labels, predicted_probs, average='macro')"
      ],
      "metadata": {
        "id": "qz8NUVQbl3cj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_finetune_model(base_model, model_name, train_gen, val_gen, fine_tune_at=-100):\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "    from sklearn.utils.class_weight import compute_class_weight\n",
        "    import time\n",
        "\n",
        "    # Step 1: Build model\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    predictions = Dense(train_gen.num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    # Freeze base model\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=Adam(1e-4),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Initial training\n",
        "    print(f\"🔧 Initial training for {model_name}...\")\n",
        "    start_time = time.time()\n",
        "    history_initial = model.fit(train_gen,\n",
        "                                epochs=10,\n",
        "                                validation_data=val_gen,\n",
        "                                verbose=1)\n",
        "    init_time = time.time() - start_time\n",
        "\n",
        "    # Fine-tuning\n",
        "    print(f\"🔁 Fine-tuning {model_name}...\")\n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable = False\n",
        "    for layer in base_model.layers[fine_tune_at:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    model.compile(optimizer=Adam(1e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Class weights\n",
        "    class_weights = compute_class_weight(class_weight='balanced',\n",
        "                                         classes=np.unique(train_gen.classes),\n",
        "                                         y=train_gen.classes)\n",
        "    class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "\n",
        "    # Fine-tune training\n",
        "    start_finetune = time.time()\n",
        "    history_finetune = model.fit(train_gen,\n",
        "                                 epochs=40,\n",
        "                                 validation_data=val_gen,\n",
        "                                 class_weight=class_weight_dict,\n",
        "                                 verbose=1)\n",
        "    finetune_time = time.time() - start_finetune\n",
        "    total_time = init_time + finetune_time\n",
        "\n",
        "    # Evaluate\n",
        "    val_loss, val_acc = model.evaluate(val_gen, verbose=0)\n",
        "    val_map = calculate_map(model, val_gen)\n",
        "\n",
        "    print(f\"\\n✅ {model_name} completed.\")\n",
        "    print(f\"⏱ Total training time: {total_time/60:.2f} mins\")\n",
        "    print(f\"📈 Accuracy: {val_acc:.4f}\")\n",
        "    print(f\"📊 mAP: {val_map:.4f}\")\n",
        "\n",
        "    return {\n",
        "        'model': model,\n",
        "        'initial_history': history_initial,\n",
        "        'finetune_history': history_finetune,\n",
        "        'val_accuracy': val_acc,\n",
        "        'val_mAP': val_map,\n",
        "        'total_time': total_time\n",
        "    }"
      ],
      "metadata": {
        "id": "BIO8EKwSjwEE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet50 model train and tune\n",
        "resnet_result = train_and_finetune_model(ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3)), \"ResNet50\", train_gen, val_gen)"
      ],
      "metadata": {
        "id": "T0xqd3wdpmrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f549a6-7d49-44ac-87fb-46534844c067"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "🔧 Initial training for ResNet50...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 744ms/step - accuracy: 0.1718 - loss: 2.0546 - val_accuracy: 0.2318 - val_loss: 1.7691\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 544ms/step - accuracy: 0.1790 - loss: 1.8947 - val_accuracy: 0.2433 - val_loss: 1.7817\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 715ms/step - accuracy: 0.2139 - loss: 1.8428 - val_accuracy: 0.2395 - val_loss: 1.7588\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 677ms/step - accuracy: 0.2244 - loss: 1.7873 - val_accuracy: 0.2375 - val_loss: 1.7514\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 512ms/step - accuracy: 0.2353 - loss: 1.7694 - val_accuracy: 0.2356 - val_loss: 1.7492\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 487ms/step - accuracy: 0.2299 - loss: 1.7811 - val_accuracy: 0.2356 - val_loss: 1.7482\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 494ms/step - accuracy: 0.2203 - loss: 1.7733 - val_accuracy: 0.2490 - val_loss: 1.7522\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 493ms/step - accuracy: 0.2331 - loss: 1.7591 - val_accuracy: 0.2433 - val_loss: 1.7471\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 492ms/step - accuracy: 0.2298 - loss: 1.7708 - val_accuracy: 0.2471 - val_loss: 1.7508\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 492ms/step - accuracy: 0.2331 - loss: 1.7618 - val_accuracy: 0.2414 - val_loss: 1.7455\n",
            "🔁 Fine-tuning ResNet50...\n",
            "Epoch 1/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 766ms/step - accuracy: 0.1813 - loss: 2.5658 - val_accuracy: 0.1724 - val_loss: 2.4980\n",
            "Epoch 2/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 531ms/step - accuracy: 0.1871 - loss: 1.8791 - val_accuracy: 0.1724 - val_loss: 2.2612\n",
            "Epoch 3/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.2000 - loss: 1.8256 - val_accuracy: 0.1743 - val_loss: 1.8897\n",
            "Epoch 4/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 542ms/step - accuracy: 0.2039 - loss: 1.8067 - val_accuracy: 0.1782 - val_loss: 1.7971\n",
            "Epoch 5/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 532ms/step - accuracy: 0.2198 - loss: 1.7662 - val_accuracy: 0.2452 - val_loss: 1.7289\n",
            "Epoch 6/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.2493 - loss: 1.7431 - val_accuracy: 0.2778 - val_loss: 1.7075\n",
            "Epoch 7/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 530ms/step - accuracy: 0.2751 - loss: 1.7276 - val_accuracy: 0.2529 - val_loss: 1.7052\n",
            "Epoch 8/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.2619 - loss: 1.7346 - val_accuracy: 0.2950 - val_loss: 1.6750\n",
            "Epoch 9/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.2727 - loss: 1.6950 - val_accuracy: 0.2663 - val_loss: 1.6918\n",
            "Epoch 10/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.2688 - loss: 1.6931 - val_accuracy: 0.3295 - val_loss: 1.6354\n",
            "Epoch 11/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 521ms/step - accuracy: 0.2388 - loss: 1.7201 - val_accuracy: 0.2816 - val_loss: 1.6627\n",
            "Epoch 12/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 521ms/step - accuracy: 0.2894 - loss: 1.6831 - val_accuracy: 0.2874 - val_loss: 1.6620\n",
            "Epoch 13/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 519ms/step - accuracy: 0.2934 - loss: 1.6696 - val_accuracy: 0.3008 - val_loss: 1.6321\n",
            "Epoch 14/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.2943 - loss: 1.6862 - val_accuracy: 0.3295 - val_loss: 1.6470\n",
            "Epoch 15/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.2881 - loss: 1.6880 - val_accuracy: 0.3582 - val_loss: 1.6057\n",
            "Epoch 16/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 518ms/step - accuracy: 0.2984 - loss: 1.6334 - val_accuracy: 0.2874 - val_loss: 1.6476\n",
            "Epoch 17/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 518ms/step - accuracy: 0.3412 - loss: 1.6125 - val_accuracy: 0.3276 - val_loss: 1.6129\n",
            "Epoch 18/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 531ms/step - accuracy: 0.3035 - loss: 1.6547 - val_accuracy: 0.3008 - val_loss: 1.6224\n",
            "Epoch 19/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 518ms/step - accuracy: 0.3143 - loss: 1.6362 - val_accuracy: 0.3295 - val_loss: 1.6014\n",
            "Epoch 20/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.3000 - loss: 1.6468 - val_accuracy: 0.3410 - val_loss: 1.6062\n",
            "Epoch 21/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.3129 - loss: 1.6426 - val_accuracy: 0.3544 - val_loss: 1.5740\n",
            "Epoch 22/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.3222 - loss: 1.6188 - val_accuracy: 0.3506 - val_loss: 1.5771\n",
            "Epoch 23/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 521ms/step - accuracy: 0.3442 - loss: 1.6125 - val_accuracy: 0.3372 - val_loss: 1.5922\n",
            "Epoch 24/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.3192 - loss: 1.6126 - val_accuracy: 0.2835 - val_loss: 1.6814\n",
            "Epoch 25/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 517ms/step - accuracy: 0.3081 - loss: 1.6333 - val_accuracy: 0.3448 - val_loss: 1.5900\n",
            "Epoch 26/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 513ms/step - accuracy: 0.3413 - loss: 1.6064 - val_accuracy: 0.3257 - val_loss: 1.5860\n",
            "Epoch 27/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 523ms/step - accuracy: 0.3111 - loss: 1.5992 - val_accuracy: 0.3218 - val_loss: 1.6329\n",
            "Epoch 28/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 525ms/step - accuracy: 0.3362 - loss: 1.5986 - val_accuracy: 0.3678 - val_loss: 1.5474\n",
            "Epoch 29/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 524ms/step - accuracy: 0.3282 - loss: 1.6151 - val_accuracy: 0.3621 - val_loss: 1.5576\n",
            "Epoch 30/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 520ms/step - accuracy: 0.3458 - loss: 1.5783 - val_accuracy: 0.3582 - val_loss: 1.5937\n",
            "Epoch 31/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 520ms/step - accuracy: 0.3537 - loss: 1.5713 - val_accuracy: 0.3697 - val_loss: 1.5499\n",
            "Epoch 32/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.3505 - loss: 1.5791 - val_accuracy: 0.3812 - val_loss: 1.5368\n",
            "Epoch 33/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 518ms/step - accuracy: 0.3461 - loss: 1.5788 - val_accuracy: 0.3602 - val_loss: 1.5606\n",
            "Epoch 34/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.3607 - loss: 1.5453 - val_accuracy: 0.3985 - val_loss: 1.5153\n",
            "Epoch 35/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 516ms/step - accuracy: 0.3572 - loss: 1.5781 - val_accuracy: 0.3812 - val_loss: 1.5349\n",
            "Epoch 36/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 517ms/step - accuracy: 0.3659 - loss: 1.5325 - val_accuracy: 0.4080 - val_loss: 1.5191\n",
            "Epoch 37/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 516ms/step - accuracy: 0.3599 - loss: 1.5648 - val_accuracy: 0.3851 - val_loss: 1.5480\n",
            "Epoch 38/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 515ms/step - accuracy: 0.3658 - loss: 1.5548 - val_accuracy: 0.3736 - val_loss: 1.5472\n",
            "Epoch 39/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 522ms/step - accuracy: 0.3705 - loss: 1.5405 - val_accuracy: 0.4100 - val_loss: 1.5239\n",
            "Epoch 40/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 523ms/step - accuracy: 0.3695 - loss: 1.5428 - val_accuracy: 0.3927 - val_loss: 1.5122\n",
            "\n",
            "✅ ResNet50 completed.\n",
            "⏱ Total training time: 37.14 mins\n",
            "📈 Accuracy: 0.3927\n",
            "📊 mAP: 0.4339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#densenet121 model train and tune\n",
        "densenet_result = train_and_finetune_model(DenseNet121(include_top=False, weights='imagenet', input_shape=(224, 224, 3)), \"DenseNet121\", train_gen, val_gen)"
      ],
      "metadata": {
        "id": "JXDa8kdkqnmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc4e86f8-78b8-45d8-89c5-25476757e316"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "🔧 Initial training for DenseNet121...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 905ms/step - accuracy: 0.1744 - loss: 2.2015 - val_accuracy: 0.2931 - val_loss: 1.6904\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 494ms/step - accuracy: 0.2719 - loss: 1.8021 - val_accuracy: 0.3755 - val_loss: 1.5977\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 483ms/step - accuracy: 0.3155 - loss: 1.6616 - val_accuracy: 0.4119 - val_loss: 1.5433\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 467ms/step - accuracy: 0.3463 - loss: 1.5983 - val_accuracy: 0.4215 - val_loss: 1.5054\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 483ms/step - accuracy: 0.3844 - loss: 1.5518 - val_accuracy: 0.4291 - val_loss: 1.4745\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 485ms/step - accuracy: 0.3755 - loss: 1.5401 - val_accuracy: 0.4368 - val_loss: 1.4529\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 482ms/step - accuracy: 0.4259 - loss: 1.4843 - val_accuracy: 0.4444 - val_loss: 1.4249\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 478ms/step - accuracy: 0.4264 - loss: 1.4434 - val_accuracy: 0.4579 - val_loss: 1.4028\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 487ms/step - accuracy: 0.4287 - loss: 1.4608 - val_accuracy: 0.4598 - val_loss: 1.3793\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 486ms/step - accuracy: 0.4719 - loss: 1.3949 - val_accuracy: 0.4674 - val_loss: 1.3791\n",
            "🔁 Fine-tuning DenseNet121...\n",
            "Epoch 1/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 1s/step - accuracy: 0.3351 - loss: 1.6339 - val_accuracy: 0.4693 - val_loss: 1.3786\n",
            "Epoch 2/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 492ms/step - accuracy: 0.3890 - loss: 1.4983 - val_accuracy: 0.4885 - val_loss: 1.3726\n",
            "Epoch 3/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 497ms/step - accuracy: 0.4534 - loss: 1.4565 - val_accuracy: 0.4751 - val_loss: 1.3652\n",
            "Epoch 4/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 486ms/step - accuracy: 0.4340 - loss: 1.4360 - val_accuracy: 0.4770 - val_loss: 1.3579\n",
            "Epoch 5/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 472ms/step - accuracy: 0.4515 - loss: 1.4150 - val_accuracy: 0.4828 - val_loss: 1.3503\n",
            "Epoch 6/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 487ms/step - accuracy: 0.4502 - loss: 1.3950 - val_accuracy: 0.4904 - val_loss: 1.3411\n",
            "Epoch 7/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 487ms/step - accuracy: 0.4402 - loss: 1.4078 - val_accuracy: 0.4962 - val_loss: 1.3313\n",
            "Epoch 8/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 488ms/step - accuracy: 0.4672 - loss: 1.3589 - val_accuracy: 0.4981 - val_loss: 1.3214\n",
            "Epoch 9/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 501ms/step - accuracy: 0.4802 - loss: 1.3566 - val_accuracy: 0.5134 - val_loss: 1.3122\n",
            "Epoch 10/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 496ms/step - accuracy: 0.4887 - loss: 1.3318 - val_accuracy: 0.5192 - val_loss: 1.3043\n",
            "Epoch 11/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 475ms/step - accuracy: 0.4852 - loss: 1.3162 - val_accuracy: 0.5211 - val_loss: 1.2937\n",
            "Epoch 12/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 490ms/step - accuracy: 0.5036 - loss: 1.3120 - val_accuracy: 0.5307 - val_loss: 1.2830\n",
            "Epoch 13/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 473ms/step - accuracy: 0.5064 - loss: 1.2955 - val_accuracy: 0.5268 - val_loss: 1.2771\n",
            "Epoch 14/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 485ms/step - accuracy: 0.5191 - loss: 1.2713 - val_accuracy: 0.5230 - val_loss: 1.2717\n",
            "Epoch 15/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 488ms/step - accuracy: 0.5198 - loss: 1.2643 - val_accuracy: 0.5287 - val_loss: 1.2639\n",
            "Epoch 16/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 491ms/step - accuracy: 0.5256 - loss: 1.2486 - val_accuracy: 0.5364 - val_loss: 1.2572\n",
            "Epoch 17/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 491ms/step - accuracy: 0.5266 - loss: 1.2692 - val_accuracy: 0.5383 - val_loss: 1.2514\n",
            "Epoch 18/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 491ms/step - accuracy: 0.5358 - loss: 1.2527 - val_accuracy: 0.5402 - val_loss: 1.2446\n",
            "Epoch 19/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 472ms/step - accuracy: 0.5387 - loss: 1.2259 - val_accuracy: 0.5441 - val_loss: 1.2412\n",
            "Epoch 20/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 493ms/step - accuracy: 0.5498 - loss: 1.2078 - val_accuracy: 0.5421 - val_loss: 1.2368\n",
            "Epoch 21/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 497ms/step - accuracy: 0.5406 - loss: 1.2061 - val_accuracy: 0.5498 - val_loss: 1.2265\n",
            "Epoch 22/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 479ms/step - accuracy: 0.5665 - loss: 1.1627 - val_accuracy: 0.5536 - val_loss: 1.2199\n",
            "Epoch 23/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 481ms/step - accuracy: 0.5631 - loss: 1.1728 - val_accuracy: 0.5517 - val_loss: 1.2134\n",
            "Epoch 24/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 495ms/step - accuracy: 0.5550 - loss: 1.2046 - val_accuracy: 0.5517 - val_loss: 1.2121\n",
            "Epoch 25/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 496ms/step - accuracy: 0.5457 - loss: 1.1807 - val_accuracy: 0.5632 - val_loss: 1.2067\n",
            "Epoch 26/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 497ms/step - accuracy: 0.5801 - loss: 1.1218 - val_accuracy: 0.5556 - val_loss: 1.1997\n",
            "Epoch 27/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 499ms/step - accuracy: 0.5843 - loss: 1.1060 - val_accuracy: 0.5632 - val_loss: 1.1962\n",
            "Epoch 28/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 504ms/step - accuracy: 0.5502 - loss: 1.1480 - val_accuracy: 0.5575 - val_loss: 1.1946\n",
            "Epoch 29/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 493ms/step - accuracy: 0.6028 - loss: 1.0669 - val_accuracy: 0.5594 - val_loss: 1.1917\n",
            "Epoch 30/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 499ms/step - accuracy: 0.5900 - loss: 1.1124 - val_accuracy: 0.5670 - val_loss: 1.1878\n",
            "Epoch 31/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 484ms/step - accuracy: 0.5965 - loss: 1.0838 - val_accuracy: 0.5651 - val_loss: 1.1848\n",
            "Epoch 32/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 494ms/step - accuracy: 0.5923 - loss: 1.1116 - val_accuracy: 0.5632 - val_loss: 1.1784\n",
            "Epoch 33/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 485ms/step - accuracy: 0.5954 - loss: 1.0750 - val_accuracy: 0.5651 - val_loss: 1.1724\n",
            "Epoch 34/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 506ms/step - accuracy: 0.6120 - loss: 1.0547 - val_accuracy: 0.5632 - val_loss: 1.1705\n",
            "Epoch 35/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 504ms/step - accuracy: 0.5876 - loss: 1.1044 - val_accuracy: 0.5613 - val_loss: 1.1637\n",
            "Epoch 36/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 502ms/step - accuracy: 0.6005 - loss: 1.0715 - val_accuracy: 0.5651 - val_loss: 1.1607\n",
            "Epoch 37/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 498ms/step - accuracy: 0.6021 - loss: 1.0366 - val_accuracy: 0.5613 - val_loss: 1.1587\n",
            "Epoch 38/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 499ms/step - accuracy: 0.6029 - loss: 1.0612 - val_accuracy: 0.5670 - val_loss: 1.1517\n",
            "Epoch 39/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 498ms/step - accuracy: 0.6325 - loss: 1.0008 - val_accuracy: 0.5728 - val_loss: 1.1523\n",
            "Epoch 40/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 505ms/step - accuracy: 0.6246 - loss: 1.0198 - val_accuracy: 0.5766 - val_loss: 1.1468\n",
            "\n",
            "✅ DenseNet121 completed.\n",
            "⏱ Total training time: 34.90 mins\n",
            "📈 Accuracy: 0.5766\n",
            "📊 mAP: 0.6283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mobilenetv3 model train and tune\n",
        "mobilenet_result = train_and_finetune_model(MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(224, 224, 3)), \"MobileNetV3Large\", train_gen, val_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R56Yrj91lyn4",
        "outputId": "1df1b0f9-e9c4-4cab-950b-a994f2d3ca3b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_large_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m12683000/12683000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "🔧 Initial training for MobileNetV3Large...\n",
            "Epoch 1/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 665ms/step - accuracy: 0.1839 - loss: 1.9187 - val_accuracy: 0.2280 - val_loss: 1.7719\n",
            "Epoch 2/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 465ms/step - accuracy: 0.2102 - loss: 1.8178 - val_accuracy: 0.2299 - val_loss: 1.7690\n",
            "Epoch 3/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 469ms/step - accuracy: 0.1968 - loss: 1.8364 - val_accuracy: 0.2337 - val_loss: 1.7699\n",
            "Epoch 4/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 448ms/step - accuracy: 0.1996 - loss: 1.8260 - val_accuracy: 0.2318 - val_loss: 1.7644\n",
            "Epoch 5/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 470ms/step - accuracy: 0.2120 - loss: 1.8083 - val_accuracy: 0.2433 - val_loss: 1.7639\n",
            "Epoch 6/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 470ms/step - accuracy: 0.2123 - loss: 1.8019 - val_accuracy: 0.2146 - val_loss: 1.7689\n",
            "Epoch 7/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 451ms/step - accuracy: 0.1921 - loss: 1.7988 - val_accuracy: 0.2452 - val_loss: 1.7602\n",
            "Epoch 8/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 473ms/step - accuracy: 0.2026 - loss: 1.7977 - val_accuracy: 0.2529 - val_loss: 1.7633\n",
            "Epoch 9/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 473ms/step - accuracy: 0.2082 - loss: 1.7845 - val_accuracy: 0.2395 - val_loss: 1.7572\n",
            "Epoch 10/10\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 462ms/step - accuracy: 0.2247 - loss: 1.7732 - val_accuracy: 0.2471 - val_loss: 1.7607\n",
            "🔁 Fine-tuning MobileNetV3Large...\n",
            "Epoch 1/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 755ms/step - accuracy: 0.2178 - loss: 2.7493 - val_accuracy: 0.1743 - val_loss: 1.7738\n",
            "Epoch 2/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 488ms/step - accuracy: 0.2053 - loss: 1.9786 - val_accuracy: 0.1705 - val_loss: 1.7790\n",
            "Epoch 3/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 467ms/step - accuracy: 0.1913 - loss: 1.8848 - val_accuracy: 0.1667 - val_loss: 1.7763\n",
            "Epoch 4/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 457ms/step - accuracy: 0.1831 - loss: 1.8391 - val_accuracy: 0.1667 - val_loss: 1.7740\n",
            "Epoch 5/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 499ms/step - accuracy: 0.1901 - loss: 1.8427 - val_accuracy: 0.1667 - val_loss: 1.7726\n",
            "Epoch 6/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 489ms/step - accuracy: 0.1884 - loss: 1.8413 - val_accuracy: 0.1648 - val_loss: 1.7733\n",
            "Epoch 7/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 481ms/step - accuracy: 0.1870 - loss: 1.8160 - val_accuracy: 0.1820 - val_loss: 1.7753\n",
            "Epoch 8/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 462ms/step - accuracy: 0.2178 - loss: 1.7991 - val_accuracy: 0.1916 - val_loss: 1.7753\n",
            "Epoch 9/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 479ms/step - accuracy: 0.1971 - loss: 1.8060 - val_accuracy: 0.2299 - val_loss: 1.7743\n",
            "Epoch 10/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 484ms/step - accuracy: 0.2189 - loss: 1.7714 - val_accuracy: 0.2299 - val_loss: 1.7731\n",
            "Epoch 11/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 476ms/step - accuracy: 0.2080 - loss: 1.7864 - val_accuracy: 0.2318 - val_loss: 1.7734\n",
            "Epoch 12/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 460ms/step - accuracy: 0.2369 - loss: 1.7635 - val_accuracy: 0.2337 - val_loss: 1.7749\n",
            "Epoch 13/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 477ms/step - accuracy: 0.2194 - loss: 1.7825 - val_accuracy: 0.2299 - val_loss: 1.7773\n",
            "Epoch 14/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 477ms/step - accuracy: 0.2286 - loss: 1.7626 - val_accuracy: 0.2241 - val_loss: 1.7808\n",
            "Epoch 15/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 464ms/step - accuracy: 0.2418 - loss: 1.7593 - val_accuracy: 0.2241 - val_loss: 1.7841\n",
            "Epoch 16/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 483ms/step - accuracy: 0.2329 - loss: 1.7490 - val_accuracy: 0.2356 - val_loss: 1.7883\n",
            "Epoch 17/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 464ms/step - accuracy: 0.2520 - loss: 1.7379 - val_accuracy: 0.2395 - val_loss: 1.7896\n",
            "Epoch 18/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 479ms/step - accuracy: 0.2478 - loss: 1.7652 - val_accuracy: 0.2452 - val_loss: 1.7964\n",
            "Epoch 19/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 478ms/step - accuracy: 0.2840 - loss: 1.7292 - val_accuracy: 0.2356 - val_loss: 1.8014\n",
            "Epoch 20/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 474ms/step - accuracy: 0.2512 - loss: 1.7293 - val_accuracy: 0.2261 - val_loss: 1.8032\n",
            "Epoch 21/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 458ms/step - accuracy: 0.2605 - loss: 1.7294 - val_accuracy: 0.2184 - val_loss: 1.8087\n",
            "Epoch 22/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 481ms/step - accuracy: 0.2643 - loss: 1.7007 - val_accuracy: 0.2126 - val_loss: 1.8055\n",
            "Epoch 23/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 484ms/step - accuracy: 0.2937 - loss: 1.7073 - val_accuracy: 0.2299 - val_loss: 1.8060\n",
            "Epoch 24/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 474ms/step - accuracy: 0.2731 - loss: 1.7082 - val_accuracy: 0.2337 - val_loss: 1.7969\n",
            "Epoch 25/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 470ms/step - accuracy: 0.2771 - loss: 1.7229 - val_accuracy: 0.2280 - val_loss: 1.7947\n",
            "Epoch 26/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 481ms/step - accuracy: 0.2793 - loss: 1.7140 - val_accuracy: 0.2299 - val_loss: 1.7857\n",
            "Epoch 27/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 482ms/step - accuracy: 0.2735 - loss: 1.7228 - val_accuracy: 0.2261 - val_loss: 1.7832\n",
            "Epoch 28/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 479ms/step - accuracy: 0.3000 - loss: 1.6946 - val_accuracy: 0.2299 - val_loss: 1.7794\n",
            "Epoch 29/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 484ms/step - accuracy: 0.2656 - loss: 1.7035 - val_accuracy: 0.2356 - val_loss: 1.7733\n",
            "Epoch 30/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 466ms/step - accuracy: 0.2832 - loss: 1.6900 - val_accuracy: 0.2375 - val_loss: 1.7675\n",
            "Epoch 31/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 483ms/step - accuracy: 0.2704 - loss: 1.6882 - val_accuracy: 0.2356 - val_loss: 1.7591\n",
            "Epoch 32/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 494ms/step - accuracy: 0.2938 - loss: 1.6709 - val_accuracy: 0.2452 - val_loss: 1.7474\n",
            "Epoch 33/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 492ms/step - accuracy: 0.3059 - loss: 1.6793 - val_accuracy: 0.2241 - val_loss: 1.7428\n",
            "Epoch 34/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 464ms/step - accuracy: 0.2956 - loss: 1.6672 - val_accuracy: 0.2299 - val_loss: 1.7409\n",
            "Epoch 35/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 472ms/step - accuracy: 0.2883 - loss: 1.6842 - val_accuracy: 0.2395 - val_loss: 1.7335\n",
            "Epoch 36/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 552ms/step - accuracy: 0.3014 - loss: 1.6742 - val_accuracy: 0.2375 - val_loss: 1.7253\n",
            "Epoch 37/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 487ms/step - accuracy: 0.2894 - loss: 1.6920 - val_accuracy: 0.2337 - val_loss: 1.7222\n",
            "Epoch 38/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 466ms/step - accuracy: 0.2922 - loss: 1.6797 - val_accuracy: 0.2318 - val_loss: 1.7139\n",
            "Epoch 39/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 478ms/step - accuracy: 0.3055 - loss: 1.6502 - val_accuracy: 0.2414 - val_loss: 1.7098\n",
            "Epoch 40/40\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 459ms/step - accuracy: 0.3146 - loss: 1.6628 - val_accuracy: 0.2490 - val_loss: 1.7003\n",
            "\n",
            "✅ MobileNetV3Large completed.\n",
            "⏱ Total training time: 33.39 mins\n",
            "📈 Accuracy: 0.2490\n",
            "📊 mAP: 0.2977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll0JgF7J3YBo",
        "outputId": "c27755e1-3715-4ac5-f451-4ad80f14644c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': <Functional name=functional, built=True>,\n",
              " 'initial_history': <keras.src.callbacks.history.History at 0x7a4801a232d0>,\n",
              " 'finetune_history': <keras.src.callbacks.history.History at 0x7a47f83c6810>,\n",
              " 'val_accuracy': 0.3927203118801117,\n",
              " 'val_mAP': np.float64(0.43386669149304047),\n",
              " 'total_time': 2228.184358358383}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8qk3N513S0p",
        "outputId": "47e895b4-22d1-4a3a-858d-003d5697f556"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': <Functional name=functional_1, built=True>,\n",
              " 'initial_history': <keras.src.callbacks.history.History at 0x7a4720d55090>,\n",
              " 'finetune_history': <keras.src.callbacks.history.History at 0x7a46fc786810>,\n",
              " 'val_accuracy': 0.5766283273696899,\n",
              " 'val_mAP': np.float64(0.6282657582870591),\n",
              " 'total_time': 2094.281471967697}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZEq35ix125u",
        "outputId": "95569592-9f2e-4f37-c1a0-2960081f8296"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': <Functional name=functional_2, built=True>,\n",
              " 'initial_history': <keras.src.callbacks.history.History at 0x7a4521ae9e90>,\n",
              " 'finetune_history': <keras.src.callbacks.history.History at 0x7a45219d9a10>,\n",
              " 'val_accuracy': 0.24904213845729828,\n",
              " 'val_mAP': np.float64(0.29772638720494365),\n",
              " 'total_time': 2003.2274901866913}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Save Pkl and .h5 for future visualization"
      ],
      "metadata": {
        "id": "vqKg_VTclkvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack from dictionary\n",
        "resnet_model = resnet_result['model']\n",
        "resnet_init_hist = resnet_result['initial_history']\n",
        "resnet_ft_hist = resnet_result['finetune_history']\n",
        "\n",
        "# Save model\n",
        "resnet_model.save(\"resnet50_tiger.h5\")\n",
        "\n",
        "# Save training and fine-tuning histories\n",
        "import pickle\n",
        "\n",
        "with open(\"resnet50_initial_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(resnet_init_hist.history, f)\n",
        "\n",
        "with open(\"resnet50_finetune_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(resnet_ft_hist.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyupzIFclzCI",
        "outputId": "58456560-8b06-4ad2-ca58-a9f31ddc113d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_metrics = {\n",
        "    'val_accuracy': resnet_result['val_accuracy'],\n",
        "    'val_mAP': resnet_result['val_mAP'],\n",
        "    'total_time': resnet_result['total_time']\n",
        "}\n",
        "\n",
        "with open(\"resnet50_performance.pkl\", \"wb\") as f:\n",
        "    pickle.dump(performance_metrics, f)"
      ],
      "metadata": {
        "id": "EOqXw3CGm-Ni"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack from dictionary\n",
        "densenet_model = densenet_result['model']\n",
        "densenet_init_hist = densenet_result['initial_history']\n",
        "densenet_ft_hist = densenet_result['finetune_history']\n",
        "\n",
        "# Save model\n",
        "densenet_model.save(\"densenet121_tiger.h5\")\n",
        "\n",
        "# Save training and fine-tuning histories\n",
        "import pickle\n",
        "\n",
        "with open(\"densenet121_initial_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(densenet_init_hist.history, f)\n",
        "\n",
        "with open(\"densenet121_finetune_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(densenet_ft_hist.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF5FkCmCnGdf",
        "outputId": "12443327-43e3-4118-f666-b924806ca811"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_metrics = {\n",
        "    'val_accuracy': densenet_result['val_accuracy'],\n",
        "    'val_mAP': densenet_result['val_mAP'],\n",
        "    'total_time': densenet_result['total_time']\n",
        "}\n",
        "\n",
        "with open(\"densenet121_performance.pkl\", \"wb\") as f:\n",
        "    pickle.dump(performance_metrics, f)"
      ],
      "metadata": {
        "id": "r_saGh3rnW8t"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpack from dictionary\n",
        "mobilenet_model = mobilenet_result['model']\n",
        "mobilenet_init_hist = mobilenet_result['initial_history']\n",
        "mobilenet_ft_hist = mobilenet_result['finetune_history']\n",
        "\n",
        "# Save model\n",
        "mobilenet_model.save(\"mobilenetv3_tiger.h5\")\n",
        "\n",
        "# Save training and fine-tuning histories\n",
        "import pickle\n",
        "\n",
        "with open(\"mobilenetv3_initial_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(mobilenet_init_hist.history, f)\n",
        "\n",
        "with open(\"mobilenetv3_finetune_history.pkl\", \"wb\") as f:\n",
        "    pickle.dump(mobilenet_ft_hist.history, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdBjaXzop0Hs",
        "outputId": "0eaba317-4646-4315-a17d-abcf5aa351f9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "performance_metrics = {\n",
        "    'val_accuracy': mobilenet_result['val_accuracy'],\n",
        "    'val_mAP': mobilenet_result['val_mAP'],\n",
        "    'total_time': mobilenet_result['total_time']\n",
        "}\n",
        "\n",
        "with open(\"mobilenetv3_performance.pkl\", \"wb\") as f:\n",
        "    pickle.dump(performance_metrics, f)"
      ],
      "metadata": {
        "id": "jdKzqTev0wom"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {\n",
        "    \"ResNet50\": resnet_result,\n",
        "    \"DenseNet121\": densenet_result,\n",
        "    \"MobileNetV3Large\": mobilenet_result\n",
        "}\n",
        "\n",
        "print(f\"{'Model':<18} {'Val Accuracy (%)':<18} {'mAP (%)':<12} {'Time (min)':<12}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for model_name, result in results.items():\n",
        "    val_acc_percent = result['val_accuracy'] * 100\n",
        "    val_map_percent = result['val_mAP'] * 100\n",
        "    time_min = result['total_time'] / 60\n",
        "    print(f\"{model_name:<18} {val_acc_percent:<18.2f} {val_map_percent:<12.2f} {time_min:<12.2f}\")"
      ],
      "metadata": {
        "id": "1HYncQNM2XEy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f235ae-6c6f-4c5b-e87e-90107c3f8be9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model              Val Accuracy (%)   mAP (%)      Time (min)  \n",
            "------------------------------------------------------------\n",
            "ResNet50           39.27              43.39        37.14       \n",
            "DenseNet121        57.66              62.83        34.90       \n",
            "MobileNetV3Large   24.90              29.77        33.39       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pwUcrX_5ASbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}